<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Hybrid-scale Heterogeneous Graph Fusion for Multimodal Intent Recognition">
  <meta property="og:title" content="H2GF-Net: Hybrid-scale Heterogeneous Graph Fusion for Multimodal Intent Recognition"/>
  
  <title>H2GF-Net</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
</head>

<body>

  <!-- Title Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1">
              H²GF-Net
            </h1>

            <h2 class="subtitle is-4">
              Hybrid-scale Heterogeneous Graph Fusion for Multimodal Intent Recognition
            </h2>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract Section -->
  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">

            Multimodal Intent Recognition (MIR) aims to infer a speaker’s communicative intent by integrating heterogeneous textual, acoustic, and visual signals. 
            However, intent-related cues are often distributed across fine-grained local variations and global semantic representations, making it challenging for 
            existing approaches to explicitly model cross-modal and local-global dependencies within a unified framework. To address this challenge, we propose the 
            Hybrid-scale Heterogeneous Graph Fusion Network (H$^2$GF-Net), which integrates affective semantic prior–guided local key information selection with 
            progressive hybrid-scale heterogeneous graph modeling for multimodal intent understanding.

          </div>
        </div>
      </div>

    </div>
  </section>

  <!-- Speech Demo Section -->
  <section class="section is-light">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Speech Demo</h2>

          <div class="content">
            <p>
              Please check our demo samples:
            </p>

          </div>
        </div>
      </div>

    </div>
  </section>

</body>
</html>
